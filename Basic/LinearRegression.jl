### A Pluto.jl notebook ###
# v0.11.14

using Markdown
using InteractiveUtils

# â•”â•â•¡ b438ab92-fefd-11ea-1054-632292d0965c
begin
	using Flux
	using Flux: @epochs
	using DataFrames
	using Gadfly
	using LinearAlgebra
	using Random
end

# â•”â•â•¡ d6e28796-fefb-11ea-1b08-bbe1e9f98682
md"# çº¿æ€§å›å½’

## åŸºæœ¬

- æ¨¡å‹
- è®­ç»ƒ
- æ•°æ®
- æŸå¤±å‡½æ•°
- ä¼˜åŒ–
***
"


# â•”â•â•¡ a3a08c06-fefc-11ea-38d3-2526f9a1ccd2
md"$y = Xw + b$"

# â•”â•â•¡ b3f67ca0-fefc-11ea-17cb-373174529e5c
md"
æ ¹æ®è¯¯å·®ï¼Œåˆ©ç”¨æ¢¯åº¦å¯¹å‚æ•°$W$å’Œ$b$è¿›è¡Œæ›´æ–°ã€‚

$W = W - \frac{lr}{batchsize} \frac{\partial L(W, b)}{\partial W}$

å…¶ä¸­$batchsize$æ˜¯æ¯æ‰¹æ•°æ®è®­ç»ƒå¤§å°ï¼Œ$lr$æ˜¯å­¦ä¹ ç‡ã€‚"

# â•”â•â•¡ 5a0fac6a-fefd-11ea-1daa-135ba73382ac
md"**ä¾‹å­**"

# â•”â•â•¡ 924bbece-fefe-11ea-3cdf-75c5fe8eb392
begin
	#prepare data
	Random.seed!(123)
	num_inputs = 2
	num_inputs = 2
	num_examples = 1000
	True_w = [2.5, 3.0]
	True_b = 4.2
	features = randn(Float64, (num_examples, num_inputs))
	labels = features * True_w .+ True_b
	labels += randn(size(labels)) * 0.05
	regData = []
	for i in 1:num_examples
  		push!(regData, (features[i,:], labels[i]))
	end

end

# â•”â•â•¡ 6293416a-feff-11ea-08f3-ab1625da01ab
x1 = reshape(features[:,1], (1, 1000))

# â•”â•â•¡ 67ef56b2-feff-11ea-0d3a-5fcfab8cd1d8
x2 = reshape(features[:, 2], (1, 1000))

# â•”â•â•¡ 00a23774-ff00-11ea-2e13-e96bf9905d60
#define Model
m = Chain(Dense(2,1))

# â•”â•â•¡ 0632bd28-ff00-11ea-3f4f-214aaf6ecf73
#define Loss function
loss(x,y) = Flux.mse(m(x), y)

# â•”â•â•¡ 1706aba0-ff00-11ea-12b7-159a1cc6ca0a
#opt
opt = Descent(0.3)


# â•”â•â•¡ 32f1e2a8-ff00-11ea-2c18-95d2536c5068
@epochs 100 Flux.train!(loss, Flux.params(m), regData, opt)

# â•”â•â•¡ 537447da-ff00-11ea-1c38-a30b89cc8c10
m([x1; x2])

# â•”â•â•¡ 63707fde-ff00-11ea-2485-2b716b32b584
labels

# â•”â•â•¡ c351b254-ff00-11ea-2b8a-677da5b21bd2
plot(x=m([x1;x2]), y=labels, Guide.xlabel("Predict Value"), Guide.ylabel("reality value"), Guide.title("Pre vs Real"))

# â•”â•â•¡ 951be72a-ff01-11ea-1199-3dd0e9831890
md"
è¯¦ç»†æ­¥éª¤ï¼šğŸ‘‡

```julia
batch_size = 10
#init w, b
w = rand(2)
b = rand(1)

#learning rate
lr = 0.3

#epoch
epoch = 3

linreg(X, w, b) = X*w .+ b
#define Loss
function Loss(Å·, y)
	sum((Å· - y) .^ 2)
end

function train_model(batch_size, features, labels, w, b, lr, epoch)
	dt_row, dt_col = size(features)
	indices = 1:dt_row
	Rond_indices = Random.shuffle(indices)
	for j in 1:epoch
		for i in range(1, dt_row, step = batch_size)
			j = Rond_indices[i:min(i+batch_size, dt_row)]
			X = features[j,:]
			y = labels[j,:]
			L = Loss(linreg(X, w, b), y)
			gs = gradient(() -> Loss(linreg(X, w, b), y), Flux.params(w, b))
			w -= lr/batch_size * gs[w]
			b -= lr/batch_size * gs[b]
		end
	end
	return w,b

end

Åµ, bÌ‚ = train_model(batch_size, features, labels, w, b, lr, epoch)

pre_y = features * Åµ .+ bÌ‚

print(pre_y)

```"

# â•”â•â•¡ Cell order:
# â•Ÿâ”€d6e28796-fefb-11ea-1b08-bbe1e9f98682
# â•Ÿâ”€a3a08c06-fefc-11ea-38d3-2526f9a1ccd2
# â•Ÿâ”€b3f67ca0-fefc-11ea-17cb-373174529e5c
# â•Ÿâ”€5a0fac6a-fefd-11ea-1daa-135ba73382ac
# â• â•b438ab92-fefd-11ea-1054-632292d0965c
# â• â•924bbece-fefe-11ea-3cdf-75c5fe8eb392
# â• â•6293416a-feff-11ea-08f3-ab1625da01ab
# â• â•67ef56b2-feff-11ea-0d3a-5fcfab8cd1d8
# â• â•00a23774-ff00-11ea-2e13-e96bf9905d60
# â• â•0632bd28-ff00-11ea-3f4f-214aaf6ecf73
# â• â•1706aba0-ff00-11ea-12b7-159a1cc6ca0a
# â• â•32f1e2a8-ff00-11ea-2c18-95d2536c5068
# â• â•537447da-ff00-11ea-1c38-a30b89cc8c10
# â• â•63707fde-ff00-11ea-2485-2b716b32b584
# â• â•c351b254-ff00-11ea-2b8a-677da5b21bd2
# â•Ÿâ”€951be72a-ff01-11ea-1199-3dd0e9831890
